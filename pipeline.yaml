# PIPELINE DEFINITION
# Name: pipeline-iris
# Inputs:
#    bq_dataset: str
#    bq_table: str
#    location: str
#    project_id: str
# Outputs:
#    choose-best-model-metrics: system.Metrics
#    decision-tree-metrics: system.Metrics
#    random-forest-metrics: system.Metrics
components:
  comp-choose-best-model:
    executorLabel: exec-choose-best-model
    inputDefinitions:
      artifacts:
        decision_tree_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        random_forest_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        test_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        best_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
  comp-decision-tree:
    executorLabel: exec-decision-tree
    inputDefinitions:
      artifacts:
        train_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        output_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-load-data:
    executorLabel: exec-load-data
    inputDefinitions:
      parameters:
        bq_dataset:
          parameterType: STRING
        bq_table:
          parameterType: STRING
        project_id:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        test_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-random-forest:
    executorLabel: exec-random-forest
    inputDefinitions:
      artifacts:
        train_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        output_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-upload-model:
    executorLabel: exec-upload-model
    inputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        location:
          parameterType: STRING
        model_name:
          parameterType: STRING
        project_id:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        uploaded_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
defaultPipelineRoot: gs://ml-pipelines-kfp/pipeline_root
deploymentSpec:
  executors:
    exec-choose-best-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - choose_best_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'joblib==1.4.2' 'fsspec==2024.6.1'\
          \ 'gcsfs==2024.6.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef choose_best_model(\n    test_dataset: Input[Dataset],\n    decision_tree_model:\
          \ Input[Model],\n    random_forest_model: Input[Model],\n    metrics: Output[Metrics],\n\
          \    best_model: Output[Model],\n):\n    import joblib\n    import pandas\
          \ as pd\n    from sklearn.metrics import accuracy_score\n    import fsspec,\
          \ gcsfs\n    import pickle\n    import os\n\n    test_data = pd.read_csv(test_dataset.path)\n\
          \n    dt = joblib.load(decision_tree_model.path)\n    rf = joblib.load(random_forest_model.path)\n\
          \n    dt_pred = dt.predict(test_data.drop(\"Species\", axis=1))\n    rf_pred\
          \ = rf.predict(test_data.drop(\"Species\", axis=1))\n\n    dt_accuracy =\
          \ accuracy_score(test_data[\"Species\"], dt_pred)\n    rf_accuracy = accuracy_score(test_data[\"\
          Species\"], rf_pred)\n    print(dt_accuracy)\n    print(rf_accuracy)\n\n\
          \    metrics.log_metric(\"Decision Tree (Accuracy)\", (dt_accuracy))\n \
          \   metrics.log_metric(\"Random Forest (Accuracy)\", (rf_accuracy))\n  \
          \  print(type(rf))\n    print(best_model.path)\n    filepath=best_model.path.replace(\"\
          /gcs/\", \"gs://\")\n    filename='model.joblib'\n    fs, _ = fsspec.core.url_to_fs(filepath)\n\
          \    fs.makedirs(filepath, exist_ok=True)\n    model_uri = os.path.join(filepath,\
          \ filename)\n    with fs.open(model_uri, \"wb\") as f:\n        joblib.dump(rf,\
          \ f, protocol=pickle.HIGHEST_PROTOCOL)\n\n    # if rf_accuracy >= dt_accuracy:\n\
          \    #     joblib.dump(dt, best_model.path)\n    # else:\n    #     joblib.dump(rf,\
          \ best_model.path)\n\n"
        image: python:3.10
    exec-decision-tree:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - decision_tree
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'joblib==1.4.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef decision_tree(\n    train_dataset: Input[Dataset],\n    metrics:\
          \ Output[Metrics],\n    output_model: Output[Model],\n):\n    import joblib\n\
          \    import pandas as pd\n    from sklearn.metrics import accuracy_score\n\
          \    from sklearn.model_selection import train_test_split\n    from sklearn.tree\
          \ import DecisionTreeClassifier\n\n    train = pd.read_csv(train_dataset.path)\n\
          \n    X_train, X_test, y_train, y_test = train_test_split(\n        train.drop(\"\
          Species\", axis=1),\n        train[\"Species\"],\n        test_size=0.2,\n\
          \        random_state=42,\n    )\n\n    model = DecisionTreeClassifier()\n\
          \    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n   \
          \ acc = accuracy_score(y_test, pred)\n\n    metrics.log_metric(\"accuracy\"\
          , (acc))\n\n    joblib.dump(model, output_model.path)\n\n"
        image: python:3.10
    exec-load-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - load_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'google-cloud-bigquery==2.34.3'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef load_data(\n    project_id: str,\n    bq_dataset: str,\n    bq_table:\
          \ str,\n    train_dataset: Output[Dataset],\n    test_dataset: Output[Dataset],\n\
          ):\n    import pandas as pd\n    from google.cloud import bigquery\n   \
          \ from sklearn.model_selection import train_test_split\n\n    client = bigquery.Client()\n\
          \n    dataset_ref = bigquery.DatasetReference(project_id, bq_dataset)\n\
          \    table_ref = dataset_ref.table(bq_table)\n    table = bigquery.Table(table_ref)\n\
          \    iterable_table = client.list_rows(table).to_dataframe_iterable()\n\n\
          \    dfs = []\n    for row in iterable_table:\n        dfs.append(row)\n\
          \n    df = pd.concat(dfs, ignore_index=True)\n    del dfs\n\n    df[\"Species\"\
          ].replace(\n        {\n            \"Iris-versicolor\": 0,\n           \
          \ \"Iris-virginica\": 1,\n            \"Iris-setosa\": 2,\n        },\n\
          \        inplace=True,\n    )\n\n    X_train, X_test, y_train, y_test =\
          \ train_test_split(\n        df.drop([\"Id\",\"Species\"], axis=1),\n  \
          \      df[\"Species\"],\n        test_size=0.2,\n        random_state=42,\n\
          \    )\n\n    X_train[\"Species\"] = y_train\n    X_test[\"Species\"] =\
          \ y_test\n\n    X_train.to_csv(f\"{train_dataset.path}\", index=False)\n\
          \    X_test.to_csv(f\"{test_dataset.path}\", index=False)\n\n"
        image: python:3.10
    exec-random-forest:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - random_forest
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'joblib==1.4.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef random_forest(\n    train_dataset: Input[Dataset],\n    metrics:\
          \ Output[Metrics],\n    output_model: Output[Model],\n):\n    import joblib\n\
          \    import pandas as pd\n    from sklearn.ensemble import RandomForestClassifier\n\
          \    from sklearn.metrics import accuracy_score\n    from sklearn.model_selection\
          \ import train_test_split\n\n    train = pd.read_csv(train_dataset.path)\n\
          \n    X_train, X_test, y_train, y_test = train_test_split(\n        train.drop(\"\
          Species\", axis=1),\n        train[\"Species\"],\n        test_size=0.2,\n\
          \        random_state=42,\n    )\n\n    model = RandomForestClassifier()\n\
          \    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n   \
          \ acc = accuracy_score(y_test, pred)\n\n    metrics.log_metric(\"accuracy\"\
          , (acc))\n\n    joblib.dump(model, output_model.path)\n\n"
        image: python:3.10
    exec-upload-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - upload_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform==1.64.0'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef upload_model(\n    project_id: str,\n    location: str,\n   \
          \ model: Input[Model],\n    model_name: str,\n    uploaded_model: Output[Model]\n\
          ):\n    from google.cloud import aiplatform, aiplatform_v1\n\n    aiplatform.init(project=project_id,\
          \ location=location)\n\n    explanation_parameters =  aiplatform_v1.types.explanation.ExplanationParameters({\"\
          sampled_shapley_attribution\": {\"path_count\": 10}})\n    explanation_metadata\
          \ = aiplatform_v1.types.explanation_metadata.ExplanationMetadata(\n    \
          \                        inputs = {\n                                \"\
          SepalLengthCm\": {},\n                                \"SepalWidthCm\":\
          \ {},\n                                \"PetalLengthCm\": {},\n        \
          \                        \"PetalWidthCm\": {}\n                        \
          \    },\n                            outputs = {\n                     \
          \           \"Species\": {}\n                            }\n           \
          \             )\n\n    client = aiplatform_v1.ModelServiceClient(\n    \
          \        client_options={\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"\
          }\n    )\n\n    request = {\n        \"parent\": f\"projects/{project_id}/locations/{location}\"\
          ,\n        \"filter\": f\"display_name={model_name}\"\n    }\n    results\
          \ = list(client.list_models(request=request))\n    print(results)\n    if\
          \ results:\n        parent_model = results[0]\n    else:\n        parent_model\
          \ = None\n    print(parent_model)\n    print(parent_model.name)\n    print(model.path.replace('/gcs/','gs://')+'/model.joblib')\n\
          \    upoladed_model = aiplatform.Model.upload(                 # aiplatform.Model.upload_scikit_learn_model_file\n\
          \        artifact_uri=model.path.replace('/gcs/','gs://')+'/model.joblib',\n\
          \        parent_model=parent_model.name if parent_model else None,\n   \
          \     display_name=model_name,\n        project=project_id,\n        # explanation_parameters=explanation_parameters,\n\
          \        # explanation_metadata=explanation_metadata,\n    )\n\n"
        image: python:3.10
pipelineInfo:
  name: pipeline-iris
root:
  dag:
    outputs:
      artifacts:
        choose-best-model-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: choose-best-model
        decision-tree-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: decision-tree
        random-forest-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: random-forest
    tasks:
      choose-best-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-choose-best-model
        dependentTasks:
        - decision-tree
        - load-data
        - random-forest
        inputs:
          artifacts:
            decision_tree_model:
              taskOutputArtifact:
                outputArtifactKey: output_model
                producerTask: decision-tree
            random_forest_model:
              taskOutputArtifact:
                outputArtifactKey: output_model
                producerTask: random-forest
            test_dataset:
              taskOutputArtifact:
                outputArtifactKey: test_dataset
                producerTask: load-data
        taskInfo:
          name: Select best Model
      decision-tree:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-decision-tree
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            train_dataset:
              taskOutputArtifact:
                outputArtifactKey: train_dataset
                producerTask: load-data
        taskInfo:
          name: Decision Tree
      load-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-load-data
        inputs:
          parameters:
            bq_dataset:
              componentInputParameter: bq_dataset
            bq_table:
              componentInputParameter: bq_table
            project_id:
              componentInputParameter: project_id
        taskInfo:
          name: Load data from BigQuery
      random-forest:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-random-forest
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            train_dataset:
              taskOutputArtifact:
                outputArtifactKey: train_dataset
                producerTask: load-data
        taskInfo:
          name: Random Forest
      upload-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-upload-model
        dependentTasks:
        - choose-best-model
        inputs:
          artifacts:
            model:
              taskOutputArtifact:
                outputArtifactKey: best_model
                producerTask: choose-best-model
          parameters:
            location:
              componentInputParameter: location
            model_name:
              runtimeValue:
                constant: Iris-Classifier-XGBoost-2
            project_id:
              componentInputParameter: project_id
        taskInfo:
          name: Register Model
  inputDefinitions:
    parameters:
      bq_dataset:
        parameterType: STRING
      bq_table:
        parameterType: STRING
      location:
        parameterType: STRING
      project_id:
        parameterType: STRING
  outputDefinitions:
    artifacts:
      choose-best-model-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
      decision-tree-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
      random-forest-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.7.0
