# PIPELINE DEFINITION
# Name: pipeline-iris
# Inputs:
#    bq_dataset: str
#    bq_table: str
#    location: str
#    project_id: str
# Outputs:
#    choose-best-model-metrics: system.Metrics
#    decision-tree-metrics: system.Metrics
#    random-forest-metrics: system.Metrics
components:
  comp-choose-best-model:
    executorLabel: exec-choose-best-model
    inputDefinitions:
      artifacts:
        decision_tree_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        random_forest_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        test_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        best_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
  comp-decision-tree:
    executorLabel: exec-decision-tree
    inputDefinitions:
      artifacts:
        train_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        output_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-load-data:
    executorLabel: exec-load-data
    inputDefinitions:
      parameters:
        bq_dataset:
          parameterType: STRING
        bq_table:
          parameterType: STRING
        project_id:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        test_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-load-schema:
    executorLabel: exec-load-schema
    inputDefinitions:
      parameters:
        repo_root:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        gcs_schema:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-random-forest:
    executorLabel: exec-random-forest
    inputDefinitions:
      artifacts:
        train_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        output_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
defaultPipelineRoot: gs://ml-pipelines-kfp/pipeline_root
deploymentSpec:
  executors:
    exec-choose-best-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - choose_best_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'joblib==1.4.2' 'fsspec==2024.6.1'\
          \ 'gcsfs==2024.6.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef choose_best_model(\n    test_dataset: Input[Dataset],\n    decision_tree_model:\
          \ Input[Model],\n    random_forest_model: Input[Model],\n    metrics: Output[Metrics],\n\
          \    best_model: Output[Model],\n):\n    import joblib\n    import pandas\
          \ as pd\n    from sklearn.metrics import accuracy_score\n    import os,\
          \ pickle, fsspec, gcsfs\n\n    test_data = pd.read_csv(test_dataset.path)\n\
          \n    dt = joblib.load(decision_tree_model.path)\n    rf = joblib.load(random_forest_model.path)\n\
          \n    dt_pred = dt.predict(test_data.drop(\"Species\", axis=1))\n    rf_pred\
          \ = rf.predict(test_data.drop(\"Species\", axis=1))\n\n    dt_accuracy =\
          \ accuracy_score(test_data[\"Species\"], dt_pred)\n    rf_accuracy = accuracy_score(test_data[\"\
          Species\"], rf_pred)\n    print(dt_accuracy)\n    print(rf_accuracy)\n\n\
          \    metrics.log_metric(\"Decision Tree (Accuracy)\", (dt_accuracy))\n \
          \   metrics.log_metric(\"Random Forest (Accuracy)\", (rf_accuracy))\n\n\
          \    filepath=best_model.path.replace(\"/gcs/\", \"gs://\")\n    filename='model.joblib'\n\
          \    fs, _ = fsspec.core.url_to_fs(filepath)\n    fs.makedirs(filepath,\
          \ exist_ok=True)\n    model_uri = os.path.join(filepath, filename)\n   \
          \ with fs.open(model_uri, \"wb\") as f:\n        if rf_accuracy >= dt_accuracy:\n\
          \           joblib.dump(rf, f, protocol=pickle.HIGHEST_PROTOCOL)\n     \
          \   else:\n           joblib.dump(rf, f, protocol=pickle.HIGHEST_PROTOCOL)\n\
          \n\n    # if rf_accuracy >= dt_accuracy:\n    #     joblib.dump(dt, best_model.path)\n\
          \    # else:\n    #     joblib.dump(rf, best_model.path)\n\n"
        image: python:3.10
    exec-decision-tree:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - decision_tree
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'joblib==1.4.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef decision_tree(\n    train_dataset: Input[Dataset],\n    metrics:\
          \ Output[Metrics],\n    output_model: Output[Model],\n):\n    import joblib\n\
          \    import pandas as pd\n    from sklearn.metrics import accuracy_score\n\
          \    from sklearn.model_selection import train_test_split\n    from sklearn.tree\
          \ import DecisionTreeClassifier\n\n    train = pd.read_csv(train_dataset.path)\n\
          \n    X_train, X_test, y_train, y_test = train_test_split(\n        train.drop(\"\
          Species\", axis=1),\n        train[\"Species\"],\n        test_size=0.2,\n\
          \        random_state=42,\n    )\n\n    model = DecisionTreeClassifier()\n\
          \    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n   \
          \ acc = accuracy_score(y_test, pred)\n\n    metrics.log_metric(\"accuracy\"\
          , (acc))\n\n    joblib.dump(model, output_model.path)\n\n"
        image: python:3.10
    exec-load-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - load_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'google-cloud-bigquery==2.34.3'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef load_data(\n    project_id: str,\n    bq_dataset: str,\n    bq_table:\
          \ str,\n    train_dataset: Output[Dataset],\n    test_dataset: Output[Dataset],\n\
          ):\n    import pandas as pd\n    from google.cloud import bigquery\n   \
          \ from sklearn.model_selection import train_test_split\n\n    client = bigquery.Client()\n\
          \n    dataset_ref = bigquery.DatasetReference(project_id, bq_dataset)\n\
          \    table_ref = dataset_ref.table(bq_table)\n    table = bigquery.Table(table_ref)\n\
          \    iterable_table = client.list_rows(table).to_dataframe_iterable()\n\n\
          \    dfs = []\n    for row in iterable_table:\n        dfs.append(row)\n\
          \n    df = pd.concat(dfs, ignore_index=True)\n    del dfs\n\n    df[\"Species\"\
          ].replace(\n        {\n            \"Iris-versicolor\": 0,\n           \
          \ \"Iris-virginica\": 1,\n            \"Iris-setosa\": 2,\n        },\n\
          \        inplace=True,\n    )\n\n    X_train, X_test, y_train, y_test =\
          \ train_test_split(\n        df.drop([\"Id\",\"Species\"], axis=1),\n  \
          \      df[\"Species\"],\n        test_size=0.2,\n        random_state=42,\n\
          \    )\n\n    X_train[\"Species\"] = y_train\n    X_test[\"Species\"] =\
          \ y_test\n\n    X_train.to_csv(f\"{train_dataset.path}\", index=False)\n\
          \    X_test.to_csv(f\"{test_dataset.path}\", index=False)\n\n"
        image: python:3.10
    exec-load-schema:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - load_schema
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'fsspec==2024.6.1'\
          \ 'gcsfs==2024.6.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef load_schema(\n    repo_root: str,\n    gcs_schema: Output[Artifact],\n\
          ):\n    import os\n    import fsspec\n\n    schema_path = \"/schemas/iris_xgboost\"\
          \n\n    fs, _ = fsspec.core.url_to_fs(gcs_schema.path)\n    fs.makedirs(gcs_schema.path,\
          \ exist_ok=True)\n\n    # Write serving schema into serving model directory.\n\
          \    with fs.open(os.path.join(gcs_schema.path, \"instance.yaml\"), \"w\"\
          ) as f:\n        with fsspec.open(\"schemas/iris_xgboost/vertex/instance.yaml\"\
          , \"r\") as f2: #fsspec.open(os.path.join(repo_root, \"schemas/iris_xgboost/vertex/instance.yaml\"\
          ), \"r\") as f2:\n            f.write(f2.read())\n\n    with fs.open(os.path.join(gcs_schema.path,\
          \ \"prediction.yaml\"), \"w\") as f:\n        with fsspec.open(\"schemas/iris_xgboost/vertex/prediction.yaml\"\
          , \"r\") as f2: #fsspec.open(os.path.join(repo_root, \"schemas/iris_xgboost/vertex/prediction.yaml\"\
          ), \"r\") as f2:\n            f.write(f2.read())\n\n"
        image: gcr.io/ml-pipelines-project-433602/ml-pipelines-kfp-image:main
    exec-random-forest:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - random_forest
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'joblib==1.4.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef random_forest(\n    train_dataset: Input[Dataset],\n    metrics:\
          \ Output[Metrics],\n    output_model: Output[Model],\n):\n    import joblib\n\
          \    import pandas as pd\n    from sklearn.ensemble import RandomForestClassifier\n\
          \    from sklearn.metrics import accuracy_score\n    from sklearn.model_selection\
          \ import train_test_split\n\n    train = pd.read_csv(train_dataset.path)\n\
          \n    X_train, X_test, y_train, y_test = train_test_split(\n        train.drop(\"\
          Species\", axis=1),\n        train[\"Species\"],\n        test_size=0.2,\n\
          \        random_state=42,\n    )\n\n    model = RandomForestClassifier()\n\
          \    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n   \
          \ acc = accuracy_score(y_test, pred)\n\n    metrics.log_metric(\"accuracy\"\
          , (acc))\n\n    joblib.dump(model, output_model.path)\n\n"
        image: python:3.10
pipelineInfo:
  name: pipeline-iris
root:
  dag:
    outputs:
      artifacts:
        choose-best-model-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: choose-best-model
        decision-tree-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: decision-tree
        random-forest-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: random-forest
    tasks:
      choose-best-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-choose-best-model
        dependentTasks:
        - decision-tree
        - load-data
        - load-schema
        - random-forest
        inputs:
          artifacts:
            decision_tree_model:
              taskOutputArtifact:
                outputArtifactKey: output_model
                producerTask: decision-tree
            random_forest_model:
              taskOutputArtifact:
                outputArtifactKey: output_model
                producerTask: random-forest
            test_dataset:
              taskOutputArtifact:
                outputArtifactKey: test_dataset
                producerTask: load-data
        taskInfo:
          name: Select best Model
      decision-tree:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-decision-tree
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            train_dataset:
              taskOutputArtifact:
                outputArtifactKey: train_dataset
                producerTask: load-data
        taskInfo:
          name: Decision Tree
      load-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-load-data
        inputs:
          parameters:
            bq_dataset:
              componentInputParameter: bq_dataset
            bq_table:
              componentInputParameter: bq_table
            project_id:
              componentInputParameter: project_id
        taskInfo:
          name: Load data from BigQuery
      load-schema:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-load-schema
        inputs:
          parameters:
            repo_root:
              runtimeValue:
                constant: ml_pipelines_kfp
        taskInfo:
          name: Load schema relevant to model
      random-forest:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-random-forest
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            train_dataset:
              taskOutputArtifact:
                outputArtifactKey: train_dataset
                producerTask: load-data
        taskInfo:
          name: Random Forest
  inputDefinitions:
    parameters:
      bq_dataset:
        parameterType: STRING
      bq_table:
        parameterType: STRING
      location:
        parameterType: STRING
      project_id:
        parameterType: STRING
  outputDefinitions:
    artifacts:
      choose-best-model-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
      decision-tree-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
      random-forest-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.7.0
