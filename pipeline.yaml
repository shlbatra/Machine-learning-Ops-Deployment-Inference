# PIPELINE DEFINITION
# Name: pipeline-iris
# Inputs:
#    bq_dataset: str
#    bq_table: str
#    location: str
#    project_id: str
components:
  comp-choose-best-model:
    executorLabel: exec-choose-best-model
    inputDefinitions:
      artifacts:
        decision_tree_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        random_forest_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        test_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        best_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
  comp-decision-tree:
    executorLabel: exec-decision-tree
    inputDefinitions:
      artifacts:
        train_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        output_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-deploy-blessed-model-to-fastapi:
    executorLabel: exec-deploy-blessed-model-to-fastapi
    inputDefinitions:
      parameters:
        location:
          parameterType: STRING
        model_name:
          parameterType: STRING
        project_id:
          parameterType: STRING
        service_name:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        service_endpoint:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-load-data:
    executorLabel: exec-load-data
    inputDefinitions:
      parameters:
        bq_dataset:
          parameterType: STRING
        bq_table:
          parameterType: STRING
        project_id:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        test_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-load-schema:
    executorLabel: exec-load-schema
    inputDefinitions:
      parameters:
        repo_root:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        gcs_schema:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-random-forest:
    executorLabel: exec-random-forest
    inputDefinitions:
      artifacts:
        train_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        output_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-upload-model:
    executorLabel: exec-upload-model
    inputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        schema:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        image_name:
          parameterType: STRING
        location:
          parameterType: STRING
        model_name:
          parameterType: STRING
        project_id:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        vertex_model:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
defaultPipelineRoot: gs://sb-vertex/pipeline_root
deploymentSpec:
  executors:
    exec-choose-best-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - choose_best_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'joblib==1.4.2' 'fsspec==2024.6.1'\
          \ 'gcsfs==2024.6.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef choose_best_model(\n    test_dataset: Input[Dataset],\n    decision_tree_model:\
          \ Input[Model],\n    random_forest_model: Input[Model],\n    metrics: Output[Metrics],\n\
          \    best_model: Output[Model],\n):\n    import joblib\n    import pandas\
          \ as pd\n    from sklearn.metrics import accuracy_score\n    import os,\
          \ pickle, fsspec, gcsfs\n\n    test_data = pd.read_csv(test_dataset.path)\n\
          \n    dt = joblib.load(decision_tree_model.path)\n    rf = joblib.load(random_forest_model.path)\n\
          \n    dt_pred = dt.predict(test_data.drop(\"Species\", axis=1))\n    rf_pred\
          \ = rf.predict(test_data.drop(\"Species\", axis=1))\n\n    dt_accuracy =\
          \ accuracy_score(test_data[\"Species\"], dt_pred)\n    rf_accuracy = accuracy_score(test_data[\"\
          Species\"], rf_pred)\n    print(dt_accuracy)\n    print(rf_accuracy)\n\n\
          \    metrics.log_metric(\"Decision Tree (Accuracy)\", (dt_accuracy))\n \
          \   metrics.log_metric(\"Random Forest (Accuracy)\", (rf_accuracy))\n\n\
          \    filepath=best_model.path.replace(\"/gcs/\", \"gs://\")\n    filename='model.joblib'\n\
          \    fs, _ = fsspec.core.url_to_fs(filepath)\n    fs.makedirs(filepath,\
          \ exist_ok=True)\n    model_uri = os.path.join(filepath, filename)\n   \
          \ with fs.open(model_uri, \"wb\") as f:\n        if rf_accuracy >= dt_accuracy:\n\
          \           joblib.dump(rf, f, protocol=pickle.HIGHEST_PROTOCOL)\n     \
          \      print(f\"Selected Random Forest model with accuracy: {rf_accuracy}\"\
          )\n        else:\n           joblib.dump(dt, f, protocol=pickle.HIGHEST_PROTOCOL)\n\
          \           print(f\"Selected Decision Tree model with accuracy: {dt_accuracy}\"\
          )\n\n\n    # if rf_accuracy >= dt_accuracy:\n    #     joblib.dump(dt, best_model.path)\n\
          \    # else:\n    #     joblib.dump(rf, best_model.path)\n\n"
        image: python:3.10
    exec-decision-tree:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - decision_tree
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'joblib==1.4.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef decision_tree(\n    train_dataset: Input[Dataset],\n    metrics:\
          \ Output[Metrics],\n    output_model: Output[Model],\n):\n    import joblib\n\
          \    import pandas as pd\n    from sklearn.metrics import accuracy_score\n\
          \    from sklearn.model_selection import train_test_split\n    from sklearn.tree\
          \ import DecisionTreeClassifier\n\n    train = pd.read_csv(train_dataset.path)\n\
          \n    X_train, X_test, y_train, y_test = train_test_split(\n        train.drop(\"\
          Species\", axis=1),\n        train[\"Species\"],\n        test_size=0.2,\n\
          \        random_state=42,\n    )\n\n    model = DecisionTreeClassifier()\n\
          \    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n   \
          \ acc = accuracy_score(y_test, pred)\n\n    metrics.log_metric(\"accuracy\"\
          , (acc))\n\n    joblib.dump(model, output_model.path)\n\n"
        image: python:3.10
    exec-deploy-blessed-model-to-fastapi:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - deploy_blessed_model_to_fastapi
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform>=1.59.0'\
          \ 'google-cloud-run>=0.10.0' 'google-cloud-storage>=2.10.0' 'requests>=2.31.0'\
          \ 'joblib>=1.4.2' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef deploy_blessed_model_to_fastapi(\n    project_id: str,\n    location:\
          \ str,\n    model_name: str,\n    service_name: str,\n    service_endpoint:\
          \ Output[Artifact]\n):\n    from google.cloud import aiplatform, aiplatform_v1,\
          \ run_v2, storage\n    import joblib\n    import tempfile\n    import os\n\
          \    import requests\n    import time\n\n    print(f\"Starting FastAPI deployment\
          \ for blessed model: {model_name}\")\n    print(f\"Service name: {service_name}\"\
          )\n\n    # 1. Initialize Vertex AI and find blessed model\n    aiplatform.init(project=project_id,\
          \ location=location)\n\n    client = aiplatform_v1.ModelServiceClient(\n\
          \        client_options={\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"\
          }\n    )\n    request = {\n        \"parent\": f\"projects/{project_id}/locations/{location}\"\
          ,\n        \"filter\": f\"display_name={model_name}\"\n    }\n\n    models\
          \ = list(client.list_models(request=request))\n    blessed_model = None\n\
          \n    print(f\"Found {len(models)} models with name {model_name}\")\n\n\
          \    for model in models:\n        print(f\"Model: {model.name}, Aliases:\
          \ {list(model.version_aliases)}\")\n        if \"blessed\" in model.version_aliases:\n\
          \            blessed_model = model\n            break\n\n    if not blessed_model:\n\
          \        raise ValueError(f\"No blessed version found for model {model_name}.\
          \ Available models: {[(m.name, list(m.version_aliases)) for m in models]}\"\
          )\n\n    print(f\"Found blessed model: {blessed_model.name}\")\n    print(f\"\
          Model URI: {blessed_model.artifact_uri}\")\n\n    # 2. Download joblib model\
          \ from blessed version\n    gcs_uri = blessed_model.artifact_uri\n    if\
          \ not gcs_uri.startswith('gs://'):\n        raise ValueError(f\"Expected\
          \ GCS URI, got: {gcs_uri}\")\n\n    bucket_name = gcs_uri.replace('gs://',\
          \ '').split('/')[0]\n    model_path = '/'.join(gcs_uri.replace('gs://',\
          \ '').split('/')[1:])\n\n    print(f\"Downloading model from gs://{bucket_name}/{model_path}\"\
          )\n\n    storage_client = storage.Client()\n    bucket = storage_client.bucket(bucket_name)\n\
          \n    # Download and validate the model\n    model_blob_path = f\"{model_path}/model.joblib\"\
          \n    blob = bucket.blob(model_blob_path)\n\n    if not blob.exists():\n\
          \        raise ValueError(f\"Model file not found at gs://{bucket_name}/{model_blob_path}\"\
          )\n\n    with tempfile.NamedTemporaryFile(suffix='.joblib', delete=False)\
          \ as temp_file:\n        blob.download_to_filename(temp_file.name)\n   \
          \     local_model_path = temp_file.name\n\n    print(f\"Downloaded model\
          \ to: {local_model_path}\")\n\n    # 3. Validate model can be loaded\n \
          \   try:\n        model_obj = joblib.load(local_model_path)\n        print(f\"\
          Model type: {type(model_obj)}\")\n        print(f\"Model validation successful\"\
          )\n    except Exception as e:\n        os.unlink(local_model_path)\n   \
          \     raise ValueError(f\"Model validation failed: {e}\")\n\n    # 4. Copy\
          \ model to standard deployment location\n    deployment_model_path = f\"\
          deployed-models/{service_name}/model.joblib\"\n    deployment_blob = bucket.blob(deployment_model_path)\n\
          \n    print(f\"Copying model to deployment location: gs://{bucket_name}/{deployment_model_path}\"\
          )\n    deployment_blob.upload_from_filename(local_model_path)\n\n    model_gcs_path\
          \ = f\"gs://{bucket_name}/{deployment_model_path}\"\n    print(f\"Model\
          \ available at: {model_gcs_path}\")\n\n    # 5. Deploy to Cloud Run using\
          \ pre-built generic image\n    print(f\"Deploying to Cloud Run service:\
          \ {service_name}\")\n\n    run_client = run_v2.ServicesClient()\n\n    #\
          \ Use pre-built generic FastAPI image from CI/CD\n    generic_image = FASTAPI_IMAGE_NAME\n\
          \n    service_config = {\n        \"parent\": f\"projects/{project_id}/locations/{location}\"\
          ,\n        \"service_id\": service_name,\n        \"service\": {\n     \
          \       \"template\": {\n                \"containers\": [{\n          \
          \          \"image\": generic_image,\n                    \"ports\": [{\"\
          container_port\": 8080}],\n                    \"resources\": {\n      \
          \                  \"limits\": {\n                            \"memory\"\
          : \"2Gi\",\n                            \"cpu\": \"2\"\n               \
          \         }\n                    },\n                    \"env\": [\n  \
          \                      {\"name\": \"PORT\", \"value\": \"8080\"},\n    \
          \                    {\"name\": \"MODEL_GCS_PATH\", \"value\": model_gcs_path},\n\
          \                        {\"name\": \"MODEL_NAME\", \"value\": model_name},\n\
          \                        {\"name\": \"GOOGLE_CLOUD_PROJECT\", \"value\"\
          : project_id}\n                    ]\n                }],\n            \
          \    \"scaling\": {\n                    \"min_instance_count\": 0,\n  \
          \                  \"max_instance_count\": 10\n                },\n    \
          \            \"service_account\": f\"kfp-mlops@{project_id}.iam.gserviceaccount.com\"\
          \n            },\n            \"traffic\": [{\"percent\": 100, \"type\"\
          : \"TRAFFIC_TARGET_ALLOCATION_TYPE_LATEST\"}]\n        }\n    }\n\n    try:\n\
          \        # Check if service already exists\n        try:\n            existing_service\
          \ = run_client.get_service(\n                name=f\"projects/{project_id}/locations/{location}/services/{service_name}\"\
          \n            )\n            print(f\"Service {service_name} already exists,\
          \ updating...\")\n\n            # Update existing service\n            update_service\
          \ = service_config[\"service\"]\n            update_service[\"name\"] =\
          \ existing_service.name\n\n            operation = run_client.update_service(service=update_service)\n\
          \            result = operation.result(timeout=600)\n\n        except Exception\
          \ as get_error:\n            print(f\"Service doesn't exist, creating new\
          \ one: {get_error}\")\n            # Create new service\n            operation\
          \ = run_client.create_service(request=service_config)\n            result\
          \ = operation.result(timeout=600)\n\n        service_url = result.uri\n\
          \        print(f\"Service deployed successfully to: {service_url}\")\n\n\
          \        # 6. Test deployment\n        print(\"Testing deployment...\")\n\
          \        time.sleep(30)  # Wait for service to be ready\n\n        test_payload\
          \ = {\n            \"instances\": [\n                {\"sepal_length\":\
          \ 5.1, \"sepal_width\": 3.5, \"petal_length\": 1.4, \"petal_width\": 0.2}\n\
          \            ]\n        }\n\n        try:\n            # Test health endpoint\
          \ first\n            health_response = requests.get(f\"{service_url}/health\"\
          , timeout=30)\n            print(f\"Health check status: {health_response.status_code}\"\
          )\n            if health_response.status_code == 200:\n                print(f\"\
          Health check response: {health_response.json()}\")\n\n            # Test\
          \ prediction endpoint\n            response = requests.post(\n         \
          \       f\"{service_url}/predict\", \n                json=test_payload,\n\
          \                timeout=30\n            )\n            if response.status_code\
          \ == 200:\n                print(\"Deployment test successful!\")\n    \
          \            print(f\"Prediction: {response.json()}\")\n            else:\n\
          \                print(f\"Prediction test failed: {response.status_code}\
          \ - {response.text}\")\n\n        except Exception as test_e:\n        \
          \    print(f\"Test request failed: {test_e}\")\n\n        # 7. Set output\
          \ artifact\n        service_endpoint.uri = service_url\n        service_endpoint.metadata\
          \ = {\n            \"service_name\": service_name,\n            \"model_version\"\
          : blessed_model.version_id,\n            \"model_name\": model_name,\n \
          \           \"deployment_type\": \"cloud_run_fastapi\",\n            \"\
          model_gcs_path\": model_gcs_path,\n            \"image\": generic_image\n\
          \        }\n\n        print(f\"Deployment completed successfully!\")\n \
          \       print(f\"Service URL: {service_url}\")\n        print(f\"Health\
          \ check: {service_url}/health\")\n        print(f\"Prediction endpoint:\
          \ {service_url}/predict\")\n        print(f\"Vertex AI compatible endpoint:\
          \ {service_url}/v1/models/model:predict\")\n\n    except Exception as deploy_e:\n\
          \        print(f\"Cloud Run deployment failed: {deploy_e}\")\n        raise\n\
          \    finally:\n        # 8. Cleanup temporary file\n        try:\n     \
          \       os.unlink(local_model_path)\n            print(\"Temporary model\
          \ file cleaned up\")\n        except Exception as cleanup_e:\n         \
          \   print(f\"Cleanup warning: {cleanup_e}\")\n\n"
        image: us-docker.pkg.dev/deeplearning-sahil/sahil-experiment-docker-images/ml-pipelines-kfp-image:main
    exec-load-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - load_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'google-cloud-bigquery==2.34.3'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef load_data(\n    project_id: str,\n    bq_dataset: str,\n    bq_table:\
          \ str,\n    train_dataset: Output[Dataset],\n    test_dataset: Output[Dataset],\n\
          ):\n    import pandas as pd\n    from google.cloud import bigquery\n   \
          \ from sklearn.model_selection import train_test_split\n\n    client = bigquery.Client()\n\
          \n    dataset_ref = bigquery.DatasetReference(project_id, bq_dataset)\n\
          \    table_ref = dataset_ref.table(bq_table)\n    table = bigquery.Table(table_ref)\n\
          \    iterable_table = client.list_rows(table).to_dataframe_iterable()\n\n\
          \    dfs = []\n    for row in iterable_table:\n        dfs.append(row)\n\
          \n    df = pd.concat(dfs, ignore_index=True)\n    del dfs\n\n    df[\"Species\"\
          ].replace(\n        {\n            \"Iris-versicolor\": 0,\n           \
          \ \"Iris-virginica\": 1,\n            \"Iris-setosa\": 2,\n        },\n\
          \        inplace=True,\n    )\n\n    X_train, X_test, y_train, y_test =\
          \ train_test_split(\n        df.drop([\"Species\"], axis=1),\n        df[\"\
          Species\"],\n        test_size=0.2,\n        random_state=42,\n    )\n\n\
          \    X_train[\"Species\"] = y_train\n    X_test[\"Species\"] = y_test\n\n\
          \    X_train.to_csv(f\"{train_dataset.path}\", index=False)\n    X_test.to_csv(f\"\
          {test_dataset.path}\", index=False)\n\n"
        image: python:3.10
    exec-load-schema:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - load_schema
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'fsspec==2024.6.1'\
          \ 'gcsfs==2024.6.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef load_schema(\n    repo_root: str,\n    gcs_schema: Output[Artifact],\n\
          ):\n    import os\n    import fsspec\n\n    schema_path = \"/schemas/iris_xgboost\"\
          \n\n    fs, _ = fsspec.core.url_to_fs(gcs_schema.path)\n    fs.makedirs(gcs_schema.path,\
          \ exist_ok=True)\n\n    # Write serving schema into serving model directory.\n\
          \    with fs.open(os.path.join(gcs_schema.path, \"instance.yaml\"), \"w\"\
          ) as f:\n        with fsspec.open(\"schemas/iris_xgboost/vertex/instance.yaml\"\
          , \"r\") as f2: #fsspec.open(os.path.join(repo_root, \"schemas/iris_xgboost/vertex/instance.yaml\"\
          ), \"r\") as f2:\n            f.write(f2.read())\n\n    with fs.open(os.path.join(gcs_schema.path,\
          \ \"prediction.yaml\"), \"w\") as f:\n        with fsspec.open(\"schemas/iris_xgboost/vertex/prediction.yaml\"\
          , \"r\") as f2: #fsspec.open(os.path.join(repo_root, \"schemas/iris_xgboost/vertex/prediction.yaml\"\
          ), \"r\") as f2:\n            f.write(f2.read())\n\n"
        image: us-docker.pkg.dev/deeplearning-sahil/sahil-experiment-docker-images/ml-pipelines-kfp-image:main
    exec-random-forest:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - random_forest
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.0'\
          \ 'scikit-learn==1.5.1' 'numpy==1.23.0' 'joblib==1.4.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef random_forest(\n    train_dataset: Input[Dataset],\n    metrics:\
          \ Output[Metrics],\n    output_model: Output[Model],\n):\n    import joblib\n\
          \    import pandas as pd\n    from sklearn.ensemble import RandomForestClassifier\n\
          \    from sklearn.metrics import accuracy_score\n    from sklearn.model_selection\
          \ import train_test_split\n\n    train = pd.read_csv(train_dataset.path)\n\
          \n    X_train, X_test, y_train, y_test = train_test_split(\n        train.drop(\"\
          Species\", axis=1),\n        train[\"Species\"],\n        test_size=0.2,\n\
          \        random_state=42,\n    )\n\n    model = RandomForestClassifier()\n\
          \    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n   \
          \ acc = accuracy_score(y_test, pred)\n\n    metrics.log_metric(\"accuracy\"\
          , (acc))\n\n    joblib.dump(model, output_model.path)\n\n"
        image: python:3.10
    exec-upload-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - upload_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.13.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform==1.64.0'\
          \ 'fsspec==2024.6.1' 'gcsfs==2024.6.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef upload_model(\n    project_id: str,\n    location: str,\n   \
          \ model: Input[Model],\n    schema: Input[Artifact],\n    model_name: str,\n\
          \    image_name: str,\n    vertex_model: Output[Artifact]\n):\n    from\
          \ google.cloud import aiplatform, aiplatform_v1\n    import fsspec, gcsfs\n\
          \n    aiplatform.init(project=project_id, location=location)\n\n    # Check\
          \ model exists in Registry\n\n    client = aiplatform_v1.ModelServiceClient(\n\
          \            client_options={\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"\
          }\n    )\n\n    # Get parent model if exists\n\n    request = {\n      \
          \  \"parent\": f\"projects/{project_id}/locations/{location}\",\n      \
          \  \"filter\": f\"display_name={model_name}\"\n    }\n    results = list(client.list_models(request=request))\n\
          \n    if results:\n        parent_model = results[0]\n    else:\n      \
          \  parent_model = None\n\n    # Set up container spec\n    container_spec\
          \ = aiplatform_v1.types.model.ModelContainerSpec(\n        image_uri=image_name,\n\
          \        args=[\"uvicorn\", \"src.ml_pipelines_kfp.iris_xgboost.server:app\"\
          , \"--host\", \"0.0.0.0\", \"--port\", \"8080\"],\n        ports=[{\"container_port\"\
          : 8080}],\n        predict_route=\"/predict\",\n        health_route=\"\
          /health/live\"\n    )\n\n    # Set up instance and prediction schema files\n\
          \    artifact_uri = schema.path.replace(\"/gcs/\", \"gs://\")\n    instance_schema_filename\
          \ = \"instance.yaml\"\n    prediction_schema_filename = \"prediction.yaml\"\
          \n    parameters_schema_filename = \"parameters.yaml\"\n    fs, _ = fsspec.core.url_to_fs(artifact_uri)\n\
          \    if isinstance(fs, gcsfs.GCSFileSystem):\n        instance_schema_uri\
          \ = f\"{artifact_uri}/{instance_schema_filename}\"\n        prediction_schema_uri\
          \ = f\"{artifact_uri}/{prediction_schema_filename}\"\n        parameters_schema_uri\
          \ = f\"{artifact_uri}/{parameters_schema_filename}\"\n\n        predict_schemata\
          \ = aiplatform_v1.PredictSchemata(\n            instance_schema_uri=instance_schema_uri\
          \ if fs.exists(instance_schema_uri) else None,\n            parameters_schema_uri=parameters_schema_uri\
          \ if fs.exists(parameters_schema_uri) else None,\n            prediction_schema_uri=prediction_schema_uri\
          \ if fs.exists(prediction_schema_uri) else None,\n        )\n    else:\n\
          \        predict_schemata = None\n\n    new_model = aiplatform_v1.Model(\n\
          \                display_name=model_name,\n                container_spec=container_spec,\n\
          \                artifact_uri=model.path.replace('/gcs/','gs://'),\n   \
          \             predict_schemata = predict_schemata,\n                version_aliases=[\"\
          blessed\"]\n    )\n\n\n    result = client.upload_model(\n             \
          \       request = dict(\n                        parent= f\"projects/{project_id}/locations/{location}\"\
          ,\n                        parent_model= parent_model.name if parent_model\
          \ else None,\n                        model=new_model,\n               \
          \     ),\n                    timeout=1800\n            ).result()\n\n \
          \   vertex_model.metadata[\"registered\"] = True\n    vertex_model.metadata[\"\
          alias\"] = \"blessed\"\n\n    print(f\"Model uploaded successfully:\\n{result}\"\
          )\n\n"
        image: python:3.10
pipelineInfo:
  name: pipeline-iris
root:
  dag:
    tasks:
      choose-best-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-choose-best-model
        dependentTasks:
        - decision-tree
        - load-data
        - load-schema
        - random-forest
        inputs:
          artifacts:
            decision_tree_model:
              taskOutputArtifact:
                outputArtifactKey: output_model
                producerTask: decision-tree
            random_forest_model:
              taskOutputArtifact:
                outputArtifactKey: output_model
                producerTask: random-forest
            test_dataset:
              taskOutputArtifact:
                outputArtifactKey: test_dataset
                producerTask: load-data
        taskInfo:
          name: Select best Model
      decision-tree:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-decision-tree
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            train_dataset:
              taskOutputArtifact:
                outputArtifactKey: train_dataset
                producerTask: load-data
        taskInfo:
          name: Decision Tree
      deploy-blessed-model-to-fastapi:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-deploy-blessed-model-to-fastapi
        dependentTasks:
        - upload-model
        inputs:
          parameters:
            location:
              componentInputParameter: location
            model_name:
              runtimeValue:
                constant: Iris-Classifier-XGBoost
            project_id:
              componentInputParameter: project_id
            service_name:
              runtimeValue:
                constant: iris-classifier-xgboost-service
        taskInfo:
          name: Deploy Blessed Model to FastAPI
      load-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-load-data
        inputs:
          parameters:
            bq_dataset:
              componentInputParameter: bq_dataset
            bq_table:
              componentInputParameter: bq_table
            project_id:
              componentInputParameter: project_id
        taskInfo:
          name: Load data from BigQuery
      load-schema:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-load-schema
        inputs:
          parameters:
            repo_root:
              runtimeValue:
                constant: /Users/shlba/Desktop/Docs/Study/code/ml_pipelines_kfp
        taskInfo:
          name: Load schema relevant to model
      random-forest:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-random-forest
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            train_dataset:
              taskOutputArtifact:
                outputArtifactKey: train_dataset
                producerTask: load-data
        taskInfo:
          name: Random Forest
      upload-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-upload-model
        dependentTasks:
        - choose-best-model
        - load-schema
        inputs:
          artifacts:
            model:
              taskOutputArtifact:
                outputArtifactKey: best_model
                producerTask: choose-best-model
            schema:
              taskOutputArtifact:
                outputArtifactKey: gcs_schema
                producerTask: load-schema
          parameters:
            image_name:
              runtimeValue:
                constant: us-docker.pkg.dev/deeplearning-sahil/sahil-experiment-docker-images/ml-pipelines-kfp-image:main
            location:
              componentInputParameter: location
            model_name:
              runtimeValue:
                constant: Iris-Classifier-XGBoost
            project_id:
              componentInputParameter: project_id
        taskInfo:
          name: Register Model
  inputDefinitions:
    parameters:
      bq_dataset:
        parameterType: STRING
      bq_table:
        parameterType: STRING
      location:
        parameterType: STRING
      project_id:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.13.0
